#app:
  # The default staging environment runs with 0 pipeline workers - this means data will not be gathered and aggregated.
  # For staging or low cpu environment you shouldn't enable more then 1 worker
  # once you enable the worker, you can schedule a pipeline to run on the worker using this snippet:
  # kubectl exec `kubectl get pod -l app=app -o json | jq -r '.items[0].metadata.name'` -- bin/execute_scheduled_pipeline.sh ./committees/kns_committee
  # dppWorkerConcurrency: 1

  # name of the influx DB to send metrics to
  # see comment for influxdb service below on how to enable it
  # influxDb: dpp



# user friendly database UI
# depends on DB for persistency (database name = metabase)
# after enabling, log in to complete the initial sign-up and setup
#metabase:
#  enabled: true

# time series DB for metrics
#influxdb:
#  enabled: true
   # persistent disk is optional - you can leave commented and loose historical metrics on every new pod
#  gcePersistentDiskName: knesset-data-pipelines-staging-influxdb

# time series DB visualization UI
# depends on DB for persistenct (database name = grafana)
#grafana:
#  enabled: true

# web server - to allow mounting services as paths of a main domain (or other configurations)
# should be enabled using the global.nginxEnabled variable
#nginx:
#  enabled: true
  # you should explicitly enable / disable sub-service mount points
#  enablePipelines: true
#  enableFlower: true
#  enableAdminer: true
#  enableMetabase: true
#  enableGrafana: true
